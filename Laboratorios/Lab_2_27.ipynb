{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Archivos/miia.jpg\" width=800x>\n",
    "\n",
    "# Laboratorio 2\n",
    "\n",
    "## Hito: desarrollo de una herramienta analítica usando paquetes especializados para análisis de datos en Python\n",
    "\n",
    "Este laboratorio corresponde al 34% de la calificación total del curso y su entrega está planteada para el final de la semana 8. Su objetivo es poner en práctica las competencias adquiridas sobre el uso de los paquetes Pandas, Seaborn y Scikit Learn, entre otros, para hacer exploración, análisis descriptivo, y abordar preguntas de negocio para un caso basado en datos reales. \n",
    "\n",
    "Especificamente, al desarrollar este laboratorio pondrás a prueba tus habilidades para:\n",
    "\n",
    "1. Identificar y abordar una pregunta de negocio a partir de un contexto dado.\n",
    "2. Cargar datos desde archivos utilizando métodos de Pandas.\n",
    "3. Explorar, manejar, limpiar y agregar DataFrames.\n",
    "5. Implementar análisis combinando métricas descriptivas, visualización, filtrado y agrupación.\n",
    "6. Implementar análisis basado en modelos estadísticos o de machine learning.\n",
    "7. Utilizar paquetes como ipywidgets o panel para agregar interactividad a los análisis de manera sencilla.\n",
    "\n",
    "Te recomendamos leer por completo el enunciado del laboratorio antes de comenzar, de forma que tengas claro el propósito completo de la actividad, y puedas desarrollar tu solución apuntando a él en cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Contexto: *Desigualdad y factores de éxito en Pruebas \"Saber 11\" (Colombia)*\n",
    "\n",
    "El ICFES es el Instituto Colombiano para el Fomento de la Educación Superior y está adscrito al Ministerio de Educación a nivel nacional. Como parte de sus funciones, el ICFES administra las pruebas *Saber 11*, las cuales evalúan a todos los estudiantes del país al final de su educación secundaria. El examen contiene preguntas que evalúan una variedad de áreas del conocimiento (p.ej., matemáticas, ciencias naturales), y se lleva a cabo dos veces al año, respondiendo a los diferentes calendarios académicos que siguen las instituciones educativas. Al momento de inscribirse a las pruebas, los estudiantes deben llenar un formulario que recoge información socio-demográfica y relacionada con la institución a la que pertenecen, con el fin de obtener evidencia respecto al desempeño de los estudiantes en la prueba según sus condiciones particulares.\n",
    "\n",
    "<img src=\"Archivos/saberpro.png\" width=700x>\n",
    "\n",
    "Al igual que otros países de la región, Colombia tiene grandes retos en términos de desigualdad, particularmente en el contexto de educación primaria y secundaria. Por esta razón, para el Estado colombiano es muy valioso el amplio registro de datos que el ICFES genera alrededor de las Pruebas Saber 11, pues con ellos se pueden generar análisis sobre la calidad de la educación en el país y eventualmente dar lugar a recomendaciones sobre políticas públicas. En particular, la problemática a abordar en este caso de estudio es *desigualdad y factores de éxito en las pruebas Saber 11*. \n",
    "\n",
    "Los objetivos de este caso de estudio son:\n",
    "\n",
    "* Entender el contenido de los archivos de datos proporcionados sobre las pruebas Saber11, generar un reporte acerca de sus características principales, e identificar qué partes de dicho contenido serán relevantes para el análisis.\n",
    "* Identificar características de las variables de interés y relaciones entre ellas, por ejemplo, a través de agrupación, visualizaciones, y descriptivos en general.\n",
    "* Abordar preguntas de negocio relacionadas con la problemática planteada, particularmente con respecto a los factores que puedan incidir significativamente en el puntaje de una persona que presenta la prueba; especialmente aquellos que se relacionen con mal desempeño.\n",
    "* Generar una herramienta sencilla que permita a un usuario interactuar con alguno de los análisis realizados de forma relevante en el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entender el contenido de los archivos de datos\n",
    "\n",
    "Esta misión consiste en hacerse una idea general del contenido de los datos y seleccionar un segmento de ellos que tenga potencial para los análisis propuestos.\n",
    "\n",
    "Pautas generales:\n",
    "* Leer los archivos de datos y agregarlos según sea necesario.\n",
    "* Inspeccionar el archivo a partir de su encabezado, columnas, descripciones de las variables según su tipo (numéricas, categóricas).\n",
    "* Definir un sub-conjunto de variables (e.g., una lista) que puedan ser relevantes para la problemática de interés.\n",
    "\n",
    "Preguntas guía:\n",
    "* ¿Qué dimensiones tienen los datos?\n",
    "* ¿Con cuántos años y periodos de evaluación se cuenta?\n",
    "* ¿Cuáles variables pueden ser de interés para la problemática planteada?\n",
    "* ¿Qué porcentaje de datos faltantes o no válidos hay en las columnas de interés? ¿Podría eso afectar el análisis, y cómo abordarlo?\n",
    "\n",
    "Esta misión corresponde a trabajo interno del analista, por lo cual no tiene un entregable para el cliente. Como entregable, puedes generar un reporte básico sobre el contenido de los archivos de datos, ya sea a través de la impresión de mensajes, la presentación de tablas resumen, u otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta\n",
    "\n",
    "**Nota:** Las decisiones tomadas tuvieron en cuenta el documento `DICCIONARIO DE VARIABLES SABER 11° PERIODO 20191 a 20202.pdf` disponible en el repositorio del ICFES.\n",
    "\n",
    "Se decidió seleccionar datos de 3 periodos de evaluación, comprendidos entre el 2019 y 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programas\\python 3.8\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "# !!!!!  Pendiente modificar esto para que cambie desde los zips\n",
    "data_20191 = pd.read_csv('SB11_20191.txt', sep=\"¬\")\n",
    "data_20192 = pd.read_csv('SB11_20192.txt', sep=\"¬\")\n",
    "data_20201 = pd.read_csv('SB11_20201.txt', sep=\"¬\")\n",
    "data_20202 = pd.read_csv('SB11_20202.txt', sep=\"¬\")\n",
    "data_20211 = pd.read_csv('SB11_20211.txt', sep=\"¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se examina el tamaño de los conjuntos de datos para cada periodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = {'20191': data_20191, '20192': data_20192, \n",
    "            '20201': data_20201, '20202': data_20202,\n",
    "            '20211': data_20211}\n",
    "\n",
    "print(\"Tamaño de cada conjunto de datos\")\n",
    "for periodo, dataset in datasets.items():\n",
    "    print(periodo, \":\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nota que existen diferencias en la forma de dataframes. La mayoría de los datos procede de los periodos 201902 y 20202, y no hay el mismo número de columnas en todos los conjuntos de datos. Para evaluar la calidad de los datos, se procede a revisar también si hay diferencias entre periodos de un mismo año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se verificará si los nombres de columnas son los mismos entre cada año.\n",
    "print(\"Los nombres de columnas son idénticos entre los 2 periodos de 2019 y 2020:\")\n",
    "for año in ('2019', '2020'):\n",
    "    print(año, \":\", all(datasets[año + '1'].columns.values == datasets[año + '2'].columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el año 2019 tiene diferencia en nombres por lo que se encontrarán los índices y nombres de las columnas discordantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_col_dif = [indice for indice, identico in enumerate(datasets['20191'].columns.values == datasets['20192'].columns.values)\n",
    "                       if identico == False]\n",
    "\n",
    "print(\"Diferencias en columnas para el año 2019:\")\n",
    "for indice in ind_col_dif:\n",
    "    print(datasets['20191'].columns[indice], datasets['20192'].columns[indice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concluye entonces que ambos dataframes del año 2019 tienen las mismas columnas, sólo que en orden diferente. Este hecho no supone problema, pero requiere tener cuidado al momento de hacer concatenaciones vertical, pues se deberán alinear las columnas.\n",
    "\n",
    "Se procede a abordar entonces el problema de las diferencias de columnas entre años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Diferencia de columnas (2019 respecto a 2020):\\n\",\n",
    "      set(datasets['20191'].columns.values).difference(set(datasets['20201'].columns.values)))\n",
    "\n",
    "print(\"Diferencia de columnas del (2019 respecto a 2021):\\n\",\n",
    "      set(datasets['20191'].columns.values).difference(set(datasets['20211'].columns.values)))\n",
    "\n",
    "print(\"Diferencia de columnas del (2020 respecto a 2019):\\n\",\n",
    "      set(datasets['20201'].columns.values).difference(set(datasets['20191'].columns.values)))   \n",
    "\n",
    "print(\"Diferencia de columnas del (2020 respecto a 2021):\\n\",\n",
    "      set(datasets['20201'].columns.values).difference(set(datasets['20211'].columns.values)))\n",
    "\n",
    "print(\"Diferencia de columnas del (2021 respecto a 2019):\\n\",\n",
    "      set(datasets['20211'].columns.values).difference(set(datasets['20191'].columns.values)))\n",
    "\n",
    "print(\"Diferencia de columnas del (2021 respecto a 2020):\\n\",\n",
    "      set(datasets['20211'].columns.values).difference(set(datasets['20201'].columns.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas diferencias significarían datos nulos en caso de concatenar las columnas tal cual cómo están. Para solucionar este problema se toma el siguiente curso de acción:\n",
    "\n",
    "* Descartar `ESTU_ETNIA` (grupo étnico minoritario al que pertenece el evaluado) de los conjuntos de datos del año 2019, ante la discontinuidad de esta columna para los años 2020 y 2021.\n",
    "* Descartar `ESTU_GENERACION-E` de los dataframes del 2019 y 2020, pues esta es una consecuencia del desempeño pero <u>no un factor explicativo</u> de este.\n",
    "\n",
    "* Las variables `ESTU_INSE_INDIVIDUAL` y `ESTU_NSE_INDIVIDUAL` representan el índice y nivel (respectivamente) socioeconómico del evaluado y están presentes en los conjuntos de datos del 2019 pero no en los del 2020 y 2021. Si bien potencialmente podrían ser reconstruidos mediante una regresión logística multinomial, se sospecha que la información de ambas variables puede estar altamente correlacionada con las de las variables `FAMI_ESTRATOVIVIENDA`, `FAMI_SITUACIONECONOMICA`, `FAMI_PERSONAS_HOGAR`, `FAMI_TRABAJOLABORPADRE`  y `FAMI_TRABAJOLABORMADRE`, por lo que para avanzar el análisis más rápidamente y evitar problemas de multicolinealidad si se decide utilizar una técnica de regresión lineal, se decide por el descarte de ambas.\n",
    "* Se descarta la columna `PERCENTIL_ESPECIAL_GLOBAL` pues sólo está presente en el dataframe del 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['20191'].drop(\"ESTU_ETNIA\", axis=1, inplace=True)\n",
    "datasets['20192'].drop(\"ESTU_ETNIA\", axis=1, inplace=True)\n",
    "\n",
    "datasets['20191'].drop(\"ESTU_GENERACION-E\", axis=1, inplace=True)\n",
    "datasets['20192'].drop(\"ESTU_GENERACION-E\", axis=1, inplace=True)\n",
    "datasets['20201'].drop(\"ESTU_GENERACION-E\", axis=1, inplace=True)\n",
    "datasets['20202'].drop(\"ESTU_GENERACION-E\", axis=1, inplace=True)\n",
    "\n",
    "datasets['20191'].drop([\"ESTU_INSE_INDIVIDUAL\", \"ESTU_NSE_INDIVIDUAL\"], axis=1, inplace=True)\n",
    "datasets['20192'].drop([\"ESTU_INSE_INDIVIDUAL\", \"ESTU_NSE_INDIVIDUAL\"], axis=1, inplace=True)\n",
    "datasets['20201'].drop([\"ESTU_INSE_INDIVIDUAL\", \"ESTU_NSE_INDIVIDUAL\"], axis=1, inplace=True)\n",
    "datasets['20202'].drop([\"ESTU_INSE_INDIVIDUAL\", \"ESTU_NSE_INDIVIDUAL\"], axis=1, inplace=True)\n",
    "\n",
    "datasets['20211'].drop(\"PERCENTIL_ESPECIAL_GLOBAL\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solamente queda `ESTU_NSE_ESTABLECIMIENTO` como columna discordante. Quizá pueda obtenerse mediante un cruce de los códigos de las sedes con los datos de 2019 y 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nse_establecimientos = []\n",
    "\n",
    "for periodo in datasets:\n",
    "    try:\n",
    "        temp_df = datasets[periodo][[\"COLE_COD_DANE_SEDE\", \"ESTU_NSE_ESTABLECIMIENTO\"]].copy()\n",
    "        temp_df = temp_df[datasets[periodo][\"ESTU_NSE_ESTABLECIMIENTO\"].isna() == False]\n",
    "        temp_df.drop_duplicates(subset=[\"COLE_COD_DANE_SEDE\", \"ESTU_NSE_ESTABLECIMIENTO\"],\n",
    "                                keep='first', inplace=True, ignore_index=False)\n",
    "        nse_establecimientos.append(temp_df)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "nse_establecimientos = pd.concat(nse_establecimientos, axis=0, ignore_index=True)\n",
    "nse_establecimientos.drop_duplicates(subset=[\"COLE_COD_DANE_SEDE\", \"ESTU_NSE_ESTABLECIMIENTO\"],\n",
    "                                     keep='first', inplace=True, ignore_index=False)\n",
    "\n",
    "# Se crea la columna ESTU_NSE_ESTABLECIMIENTO para el dataframe del 2021\n",
    "datasets[\"20211\"] = pd.merge(datasets[\"20211\"], nse_establecimientos, on=\"COLE_COD_DANE_SEDE\", how=\"left\")\n",
    "\n",
    "# Se reemplazan los ESTU_NSE_ESTABLECIMIENTO faltantes en los demás periodos\n",
    "\n",
    "def look(row):\n",
    "    if np.isnan(row[\"ESTU_NSE_ESTABLECIMIENTO\"]) == True:\n",
    "        try:\n",
    "            value = nse_establecimientos.loc[nse_establecimientos[\"COLE_COD_DANE_SEDE\"] == row[\"COLE_COD_DANE_SEDE\"],\n",
    "                                       \"ESTU_NSE_ESTABLECIMIENTO\"].values[0]\n",
    "            return value\n",
    "        except:\n",
    "            return np.NaN\n",
    "\n",
    "for periodo in (\"20191\", \"20192\", \"20201\", \"20202\"):\n",
    "    datasets[periodo].loc[datasets[periodo][\"ESTU_NSE_ESTABLECIMIENTO\"].isna(),\n",
    "                          \"ESTU_NSE_ESTABLECIMIENTO\"]\\\n",
    "    = datasets[periodo][datasets[periodo][\"ESTU_NSE_ESTABLECIMIENTO\"].isna()].apply(lambda row: look(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procederá a la concatenación de los dataframes de todos los años y se examina el número de valores nulos por columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list(datasets.values()), axis=0, ignore_index=True, sort=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "print(df.shape)\n",
    "print(\"Faltantes:\\n\", df.isna().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan que existen 180196 valores faltantes en la columna `COLE_BILINGUE`. Esto puede afectar las conclusiones en un potencial análisis que compare desempeño en la prueba de inglés respecto al carácter bilingüe del establecimiento educativo.\n",
    "\n",
    "Una posibilidad es que existan fallos parciales en los datos, es decir, para ciertos estudiantes no se reporta la información del caracter de su bilingüe de su colegio, pero para otros del mismo establecimiento sí: en este caso sería factible cruzar la información y recuperarla.\n",
    "\n",
    "Para el caso de fallos completos de los datos, es decir, ningún estudiante de un colegio dado tiene información del caracter de su colegio, la única forma de cubrir estos vacíos sería una investigación exhaustiva de estos establecimientos en otras fuentes, lo cual sería dispendioso: Se decide eliminar los registros con estas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.COLE_BILINGUE.isna().groupby(df.COLE_COD_DANE_SEDE, sort = False).mean()\n",
    "\n",
    "# Descarte de fallos completos\n",
    "df = df.query(\"~(COLE_COD_DANE_SEDE.isin(@groups[@groups == 1].index.values))\")\n",
    "\n",
    "# Tratamiento de datos parciales\n",
    "sedes_bilinguismo = df[~(df[\"COLE_BILINGUE\"].isna())][[\"COLE_COD_DANE_SEDE\", \"COLE_BILINGUE\"]]\n",
    "sedes_bilinguismo.drop_duplicates(subset=\"COLE_COD_DANE_SEDE\",\n",
    "                                  keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "df = pd.merge(df, sedes_bilinguismo, on=\"COLE_COD_DANE_SEDE\", how=\"left\")\n",
    "df = df.drop(\"COLE_BILINGUE_x\", axis=1, inplace=False).rename(columns = {\"COLE_BILINGUE_y\": \"COLE_BILINGUE\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se descartarán los nulos en `DESEMP_INGLES`, `PUNT_INGLES`, `PERCENTIL_INGLES`, `PERCENTIL_GLOBAL` y `ESTU_NSE_ESTABLECIMIENTO` puesto que ya no representan una porción significativa de la muestra.\n",
    "\n",
    "Se aprecia además que los faltantes de `ESTU_COD_RESIDE_DEPTO` y `ESTU_COD_RESIDE_MCPIO` tienen el mismo número que `ESTU_DEPTO_RESIDE` y `ESTU_MCPIO_RESIDE`, por lo que dicha información no es recuperable y será eliminada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df[[\"DESEMP_INGLES\", \"PUNT_INGLES\", \"PERCENTIL_INGLES\",\n",
    "              \"PERCENTIL_GLOBAL\", \"ESTU_NSE_ESTABLECIMIENTO\", \"ESTU_COD_RESIDE_DEPTO\",\n",
    "              \"ESTU_COD_RESIDE_MCPIO\"]].isna().any(axis=\"columns\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se consideran de interés las variables `ESTU_COD_DEPTO_PRESENTACION`, `ESTU_COD_MCPIO_PRESENTACION`, `ESTU_DEPTO_PRESENTACION`, `ESTU_DEPTO_RESIDE`, `ESTU_MCPIO_PRESENTACION`, `ESTU_MCPIO_RESIDE`, `COLE_CODIGO_ICFES`, `COLE_COD_DEPTO_UBICACION`, `COLE_COD_MCPIO_UBICACION` puesto que son claves externas de información que también se encuentra explícita en la tabla en forma de texto, siendo así redundantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ESTU_COD_DEPTO_PRESENTACION\", \"ESTU_COD_MCPIO_PRESENTACION\", \"ESTU_DEPTO_PRESENTACION\",\n",
    "                      \"ESTU_DEPTO_RESIDE\", \"ESTU_MCPIO_PRESENTACION\", \"ESTU_MCPIO_RESIDE\", \"COLE_CODIGO_ICFES\",\n",
    "                      \"COLE_COD_DEPTO_UBICACION\", \"COLE_COD_MCPIO_UBICACION\"], inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tampoco se consideran de interés para la problemática a las variables `ESTU_ESTADOINVESTIGACION`, `ESTU_TIPODOCUMENTO`, `ESTU_NACIONALIDAD`, `ESTU_ESTUDIANTE` y `ESTU_CONSECUTIVO`. No se tendrán en cuenta las variables con prefijo `DESEMP`, puesto que ya se cuenta con información de puntaje y percentil, y se excluirán del análisis las variables `COLE_SEDE_PRINCIPAL`, `COLE_NOMBRE_ESTABLECIMIENTO`, `COLE_NOMBRE_SEDE` y `COLE_CALENDARIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ESTU_ESTADOINVESTIGACION\", \"ESTU_TIPODOCUMENTO\", \"ESTU_NACIONALIDAD\", \"ESTU_CONSECUTIVO\",\n",
    "                      \"COLE_SEDE_PRINCIPAL\", \"COLE_NOMBRE_ESTABLECIMIENTO\", \"ESTU_ESTUDIANTE\", \"COLE_NOMBRE_SEDE\",\n",
    "                      \"COLE_CALENDARIO\"], inplace=False)\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.startswith('DESEMP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decide enfocar el estudio solamente en hábitos, nutrición, división urbana-rural y en los indicadores y percepción de la situación económica del hogar y del establecimiento educativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"COLE_AREA_UBICACION\", \"COLE_NATURALEZA\", \"ESTU_DEDICACIONINTERNET\",\n",
    "         \"ESTU_DEDICACIONLECTURADIARIA\", \"ESTU_HORASSEMANATRABAJA\", \"FAMI_COMECARNEPESCADOHUEVO\",\n",
    "         \"FAMI_COMECEREALFRUTOSLEGUMBRE\", \"FAMI_COMELECHEDERIVADOS\", \"FAMI_NUMLIBROS\", \"FAMI_ESTRATOVIVIENDA\",\n",
    "         \"FAMI_SITUACIONECONOMICA\", \"FAMI_TIENECOMPUTADOR\", \"FAMI_TIENECONSOLAVIDEOJUEGOS\", \"FAMI_TIENESERVICIOTV\",\n",
    "         \"FAMI_TIENEINTERNET\", \"PERCENTIL_C_NATURALES\", \"PERCENTIL_GLOBAL\", \"PERCENTIL_INGLES\", \"PERCENTIL_LECTURA_CRITICA\",\n",
    "         \"PERCENTIL_MATEMATICAS\", \"PERCENTIL_SOCIALES_CIUDADANAS\", \"PUNT_C_NATURALES\", \"PUNT_GLOBAL\", \"PUNT_INGLES\",\n",
    "         \"PUNT_LECTURA_CRITICA\", \"PUNT_MATEMATICAS\", \"PUNT_SOCIALES_CIUDADANAS\", \"COLE_BILINGUE\", \"ESTU_NSE_ESTABLECIMIENTO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se descartan los registros que tengan faltantes en todas las siguientes columnas: `ESTU_DEDICACIONINTERNET`, `ESTU_DEDICACIONLECTURADIARIA`, `ESTU_HORASSEMANATRABAJA`, `FAMI_COMECARNEPESCADOHUEVO`, `FAMI_COMECEREALFRUTOSLEGUMBRE`, `FAMI_COMELECHEDERIVADOS`, `FAMI_NUMLIBROS`, `FAMI_ESTRATOVIVIENDA`, `FAMI_TIENECOMPUTADOR`, `FAMI_TIENECONSOLAVIDEOJUEGOS`, `FAMI_TIENESERVICIOTV`, `FAMI_TIENEINTERNET`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df[['ESTU_DEDICACIONINTERNET', 'ESTU_DEDICACIONLECTURADIARIA', 'ESTU_HORASSEMANATRABAJA',\n",
    "              'FAMI_COMECARNEPESCADOHUEVO', 'FAMI_COMECEREALFRUTOSLEGUMBRE', 'FAMI_COMELECHEDERIVADOS',\n",
    "              'FAMI_NUMLIBROS', 'FAMI_ESTRATOVIVIENDA', 'FAMI_TIENECOMPUTADOR', 'FAMI_TIENECONSOLAVIDEOJUEGOS',\n",
    "              'FAMI_TIENESERVICIOTV', 'FAMI_TIENEINTERNET']].isna().all(axis=\"columns\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se revisan ahora la forma y faltantes del dataframe resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(\"Faltantes:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permanecen entonces las siguientes variables:\n",
    "\n",
    "* Explicativas: `COLE_AREA_UBICACION`, `ESTU_GENERO`, `COLE_NATURALEZA`, `ESTU_DEDICACIONINTERNET`, `ESTU_DEDICACIONLECTURADIARIA`, `ESTU_HORASSEMANATRABAJA`, `FAMI_COMECARNEPESCADOHUEVO`, `FAMI_COMECEREALFRUTOSLEGUMBRE`, `FAMI_COMELECHEDERIVADOS`, `FAMI_NUMLIBROS`, `FAMI_ESTRATOVIVIENDA`, `FAMI_TIENECOMPUTADOR`, `FAMI_TIENECONSOLAVIDEOJUEGOS`, `FAMI_TIENESERVICIOTV`, `FAMI_TIENEINTERNET`, `COLE_BILINGUE`, `ESTU_NSE_ESTABLECIMIENTO`.\n",
    "* Respuesta: `PERCENTIL_C_NATURALES`, `PERCENTIL_GLOBAL`, `PERCENTIL_INGLES`, `PERCENTIL_LECTURA_CRITICA`, `PERCENTIL_MATEMATICAS`, `PERCENTIL_SOCIALES_CIUDADANAS`, `PUNT_C_NATURALES`, `PUNT_GLOBAL`, `PUNT_INGLES`, `PUNT_LECTURA_CRITICA`, `PUNT_MATEMATICAS`, `PUNT_SOCIALES_CIUDADANAS`.\n",
    "\n",
    "Se decide conservar los registros con datos nulos, puesto que los que se preservan sí tienen información para una columna pero no para otra, dándole mayor potencia al análisis exploratorio de los datos; no obstante si al recurrir un análisis inferencial llegase a necesitar el uso de absolutamente todas las columnas explicativas, se descartaran aquellas filas que tengan al menos 1 dato nulo, puesto que no representan una fracción significativa de la muestra del dataframe.\n",
    "\n",
    "Ahora se verifica el tipo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Las columnas con prefijo `COLE` son almacenadas correctamente como cadenas, puesto que son variables cualitativas nominales.\n",
    "* Los columnas con prefijo `PUNT` y `PERCENTIL` son variables discretas en los archivos. Entonces `PUNT_INGLES`, `PERCENTIL_GLOBAL` y `PERCENTIL_INGLES` deben ser convertidos a enteros.\n",
    "* Las columnas con prefijos `ESTU` y `FAMI` son variables cualitativas ordinales, pero están siendo almacenadas como cadenas, por lo que deben ser convertidas a factores que siguen una jerarquía, haciendo así posible el cálculo de correlaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de PUNT_INGLES, PERCENTIL_GLOBAL y PERCENTIL_INGLES a enteros\n",
    "df[[\"PUNT_INGLES\", \"PERCENTIL_GLOBAL\", \"PERCENTIL_INGLES\"]] = df[[\"PUNT_INGLES\", \"PERCENTIL_GLOBAL\", \"PERCENTIL_INGLES\"]].astype(int)\n",
    "\n",
    "\n",
    "def codificacion_var_ordinales(df_columna, lista_cats_ordenadas):\n",
    "    columna_codificada = df_columna.astype('category')\n",
    "    columna_codificada = columna_codificada.cat.reorder_categories(lista_cats_ordenadas, ordered=True)\n",
    "    return columna_codificada.cat.codes\n",
    "\n",
    "# Categorización ordinal de las columnas con prefijos ESTU y FAMI.\n",
    "df['ESTU_CAT_DEDICACIONINTERNET'] = codificacion_var_ordinales(df['ESTU_DEDICACIONINTERNET'],\n",
    "                                                               ['No Navega Internet', '30 minutos o menos',\n",
    "                                                                'Entre 30 y 60 minutos', 'Entre 1 y 3 horas', 'Más de 3 horas'])\n",
    "\n",
    "df['ESTU_CAT_DEDICACIONLECTURADIARIA'] = codificacion_var_ordinales(df['ESTU_DEDICACIONLECTURADIARIA'],\n",
    "                                                                    ['No leo por entretenimiento', '30 minutos o menos',\n",
    "                                                                     'Entre 30 y 60 minutos', 'Entre 1 y 2 horas',\n",
    "                                                                     'Más de 2 horas'])\n",
    "\n",
    "df['ESTU_CAT_HORASSEMANATRABAJA'] = codificacion_var_ordinales(df['ESTU_HORASSEMANATRABAJA'],\n",
    "                                                               ['0', 'Menos de 10 horas', 'Entre 11 y 20 horas',\n",
    "                                                                'Entre 21 y 30 horas', 'Más de 30 horas'])\n",
    "\n",
    "df['FAMI_CAT_COMECARNEPESCADOHUEVO'] = codificacion_var_ordinales(df['FAMI_COMECARNEPESCADOHUEVO'],\n",
    "                                                                  ['Nunca o rara vez comemos eso', '1 o 2 veces por semana',\n",
    "                                                                   '3 a 5 veces por semana', 'Todos o casi todos los días'])\n",
    "\n",
    "df['FAMI_CAT_COMECEREALFRUTOSLEGUMBRE'] = codificacion_var_ordinales(df['FAMI_COMECEREALFRUTOSLEGUMBRE'],\n",
    "                                                                     ['Nunca o rara vez comemos eso', '1 o 2 veces por semana',\n",
    "                                                                      '3 a 5 veces por semana', 'Todos o casi todos los días'])\n",
    "\n",
    "df['FAMI_CAT_COMELECHEDERIVADOS'] = codificacion_var_ordinales(df['FAMI_COMELECHEDERIVADOS'],\n",
    "                                                               ['Nunca o rara vez comemos eso', '1 o 2 veces por semana',\n",
    "                                                                '3 a 5 veces por semana', 'Todos o casi todos los días'])\n",
    "\n",
    "df['FAMI_CAT_NUMLIBROS'] = codificacion_var_ordinales(df['FAMI_NUMLIBROS'],\n",
    "                                                      ['0 A 10 LIBROS', '11 A 25 LIBROS', '26 A 100 LIBROS',\n",
    "                                                       'MÁS DE 100 LIBROS'])\n",
    "\n",
    "df['FAMI_CAT_ESTRATOVIVIENDA'] = codificacion_var_ordinales(df['FAMI_ESTRATOVIVIENDA'],\n",
    "                                                            ['Sin Estrato', 'Estrato 1', 'Estrato 2', 'Estrato 3',\n",
    "                                                             'Estrato 4', 'Estrato 5', 'Estrato 6'])\n",
    "\n",
    "df['FAMI_CAT_SITUACIONECONOMICA'] = codificacion_var_ordinales(df['FAMI_SITUACIONECONOMICA'], ['Peor', 'Igual', 'Mejor'])\n",
    "\n",
    "df['FAMI_CAT_TIENECOMPUTADOR'] = codificacion_var_ordinales(df['FAMI_TIENECOMPUTADOR'], ['No', 'Si'])\n",
    "\n",
    "df['FAMI_CAT_TIENECONSOLAVIDEOJUEGOS'] = codificacion_var_ordinales(df['FAMI_TIENECONSOLAVIDEOJUEGOS'], ['No', 'Si'])\n",
    "\n",
    "df['FAMI_CAT_TIENESERVICIOTV'] = codificacion_var_ordinales(df['FAMI_TIENESERVICIOTV'], ['No', 'Si'])\n",
    "\n",
    "df['FAMI_CAT_TIENEINTERNET'] = codificacion_var_ordinales(df['FAMI_TIENEINTERNET'], ['No', 'Si'])\n",
    "\n",
    "df['ESTU_CAT_NSE_ESTABLECIMIENTO'] = codificacion_var_ordinales(df['ESTU_NSE_ESTABLECIMIENTO'], [1, 2, 3, 4])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Identificar características y relaciones en las variables\n",
    "\n",
    "Esta misión consiste en utilizar análisis descriptivos para explorar patrones o relaciones en las variables de interés para la problemática planteada.\n",
    "\n",
    "Pautas generales:\n",
    "* Utilizar Matplotlib y/o Seaborn para inspeccionar visualmente variables de interés; los métodos `distplot`, `pairplot`, `boxplot`, o `violinplot`, entre otros, pueden ser de utilidad.\n",
    "* Utilizar el método `groupby` de Pandas, en conjunto con la visualización, para proveer evidencia sobre el impacto de variables socio-demográficas de interés sobre el desempeño de los estudiantes en la prueba.\n",
    "\n",
    "Preguntas guía:\n",
    "* ¿Hay patrones de interés en las distribuciones de las variables, o en las relaciones entre ellas?\n",
    "* ¿Existe algún impacto significativo de variables socio-demográficas en los puntajes globales o por área?\n",
    "* ¿Sobre cuáles variables vale la pena hacer un análisis más profundo?\n",
    "\n",
    "El entregable de esta misión es un reporte (p.ej., un conjunto de visualizaciones) que de cuenta de los comportamientos más interesantes que se observen en las variables de interés para el contexto propuesto. El propósito de esta exploración es generar hipótesis o preguntas que guíen análisis más profundos. En ese sentido, con base en lo aprendido en esta sección, identifique las tres preguntas analíticas que plantearía con mayor prioridad, teniendo en cuenta el contexto y los datos disponibles; estas preguntas NO se deben abordar en términos de código para el laboratorio (únicamente formularse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, interesa comprobar si existe una brecha entre los colegios urbanos y rurales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 20))\n",
    "gs = GridSpec(nrows = 3, ncols = 2)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0])\n",
    "ax0 = sns.violinplot(x=\"COLE_AREA_UBICACION\", y=\"PUNT_GLOBAL\", data=df)\n",
    "plt.setp(ax0, title = 'PUNT_GLOBAL')\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "ax1 = sns.violinplot(x=\"COLE_AREA_UBICACION\", y=\"PUNT_MATEMATICAS\", data=df)\n",
    "plt.setp(ax1, title = 'PUNT_MATEMATICAS')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[2])\n",
    "ax2 = sns.violinplot(x=\"COLE_AREA_UBICACION\", y=\"PUNT_C_NATURALES\", data=df)\n",
    "plt.setp(ax2, title = 'PUNT_C_NATURALES')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[3])\n",
    "ax3 = sns.violinplot(x=\"COLE_AREA_UBICACION\", y=\"PUNT_INGLES\", data=df)\n",
    "plt.setp(ax3, title = 'PUNT_INGLES')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[4])\n",
    "ax4 = sns.violinplot(x=\"COLE_AREA_UBICACION\", y=\"PUNT_LECTURA_CRITICA\", data=df)\n",
    "plt.setp(ax4, title = 'PUNT_LECTURA_CRITICA')\n",
    "\n",
    "ax5 = fig.add_subplot(gs[5])\n",
    "ax5 = sns.violinplot(x=\"COLE_AREA_UBICACION\", y='PUNT_SOCIALES_CIUDADANAS', data=df)\n",
    "plt.setp(ax5, title = 'PUNT_SOCIALES_CIUDADANAS')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "puntajes = [\"PUNT_GLOBAL\", \"PUNT_MATEMATICAS\", \"PUNT_C_NATURALES\", \"PUNT_INGLES\", \"PUNT_LECTURA_CRITICA\",\n",
    "            'PUNT_SOCIALES_CIUDADANAS']\n",
    "\n",
    "df[puntajes + [\"COLE_AREA_UBICACION\"]].groupby(\"COLE_AREA_UBICACION\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los gráficos anteriores y la tabla de estadísticos descriptivos se observa que existe una diferencia entre las medias de las áreas geográficas, favoreciendo en todos los puntajes a los estudiantes de colegios ubicados en áreas urbanas.\n",
    "\n",
    "* La mayoría de las diferencias de las medias de puntaje en las pruebas específicas tiene una magnitud de aproximadamente 3-4 puntos, pero está se amplifica a 5 para la prueba de inglés.\n",
    "* El efecto acumulado de las diferencias genera una diferencia total de aproximadamente 10.5 puntos en el puntaje general.\n",
    "\n",
    "\n",
    "A continuación, se examina la diferencia entre puntajes de los colegios urbanos y públicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 20))\n",
    "gs = GridSpec(nrows = 3, ncols = 2)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0])\n",
    "ax0 = sns.violinplot(x=\"COLE_NATURALEZA\", y=\"PUNT_GLOBAL\", data=df)\n",
    "plt.setp(ax0, title = 'PUNT_GLOBAL')\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "ax1 = sns.violinplot(x=\"COLE_NATURALEZA\", y=\"PUNT_MATEMATICAS\", data=df)\n",
    "plt.setp(ax1, title = 'PUNT_MATEMATICAS')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[2])\n",
    "ax2 = sns.violinplot(x=\"COLE_NATURALEZA\", y=\"PUNT_C_NATURALES\", data=df)\n",
    "plt.setp(ax2, title = 'PUNT_C_NATURALES')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[3])\n",
    "ax3 = sns.violinplot(x=\"COLE_NATURALEZA\", y=\"PUNT_INGLES\", data=df)\n",
    "plt.setp(ax3, title = 'PUNT_INGLES')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[4])\n",
    "ax4 = sns.violinplot(x=\"COLE_NATURALEZA\", y=\"PUNT_LECTURA_CRITICA\", data=df)\n",
    "plt.setp(ax4, title = 'PUNT_LECTURA_CRITICA')\n",
    "\n",
    "ax5 = fig.add_subplot(gs[5])\n",
    "ax5 = sns.violinplot(x=\"COLE_NATURALEZA\", y='PUNT_SOCIALES_CIUDADANAS', data=df)\n",
    "plt.setp(ax5, title = 'PUNT_SOCIALES_CIUDADANAS')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df[puntajes + [\"COLE_NATURALEZA\"]].groupby(\"COLE_NATURALEZA\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia de puntajes mucho más acentuada por la naturaleza privada o pública del colegio.\n",
    "\n",
    "* Las medias de los colegios privados superan a la de los públicos, tanto en el puntaje general como el de las pruebas específicas.\n",
    "\n",
    "* Si se detalla la distribución de los mejores puntajes de las pruebas específicas de matemáticas, inglés, lectura crítica, ciencias naturales y competencias ciudadanas, se nota como la mayoría corresponde a puntajes de colegios privados.\n",
    "\n",
    "    * La diferencia en rendimiento es especialmente pronunciada para la prueba de inglés, donde las medias están separadas por alrededor de 10 puntos, y el cuantil 75 para los estudiantes de colegios privados es 9 puntos más alto que los de los colegios públicos.\n",
    "    \n",
    "Como siguiente paso, se evaluarán las diferencias entre niveles socioeconómicos de los establecimientos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 20))\n",
    "gs = GridSpec(nrows = 3, ncols = 2)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0])\n",
    "ax0 = sns.violinplot(x=\"ESTU_NSE_ESTABLECIMIENTO\", y=\"PUNT_GLOBAL\", data=df)\n",
    "plt.setp(ax0, title = 'PUNT_GLOBAL')\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "ax1 = sns.violinplot(x=\"ESTU_NSE_ESTABLECIMIENTO\", y=\"PUNT_MATEMATICAS\", data=df)\n",
    "plt.setp(ax1, title = 'PUNT_MATEMATICAS')\n",
    "\n",
    "ax2 = fig.add_subplot(gs[2])\n",
    "ax2 = sns.violinplot(x=\"ESTU_NSE_ESTABLECIMIENTO\", y=\"PUNT_C_NATURALES\", data=df)\n",
    "plt.setp(ax2, title = 'PUNT_C_NATURALES')\n",
    "\n",
    "ax3 = fig.add_subplot(gs[3])\n",
    "ax3 = sns.violinplot(x=\"ESTU_NSE_ESTABLECIMIENTO\", y=\"PUNT_INGLES\", data=df)\n",
    "plt.setp(ax3, title = 'PUNT_INGLES')\n",
    "\n",
    "ax4 = fig.add_subplot(gs[4])\n",
    "ax4 = sns.violinplot(x=\"ESTU_NSE_ESTABLECIMIENTO\", y=\"PUNT_LECTURA_CRITICA\", data=df)\n",
    "plt.setp(ax4, title = 'PUNT_LECTURA_CRITICA')\n",
    "\n",
    "ax5 = fig.add_subplot(gs[5])\n",
    "ax5 = sns.violinplot(x=\"ESTU_NSE_ESTABLECIMIENTO\", y='PUNT_SOCIALES_CIUDADANAS', data=df)\n",
    "plt.setp(ax5, title = 'PUNT_SOCIALES_CIUDADANAS')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df[puntajes + [\"ESTU_NSE_ESTABLECIMIENTO\"]].groupby(\"ESTU_NSE_ESTABLECIMIENTO\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df[\"FAMI_NUMLIBROS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 20))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    df.corr(), \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[~(df.isna().any(axis=\"columns\"))]\n",
    "#print(\"Faltantes:\\n\", df1.notna().sum())\n",
    "\n",
    "# Verificación de tipos de datos\n",
    "\n",
    "# Transformaciones\n",
    "\n",
    "# Subseccion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preguntas analíticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Abordar preguntas de negocio planteadas\n",
    "\n",
    "Esta misión consiste en proponer, implementar y evaluar el desempeño modelo(s) que busque(n) explicar las relaciones entre factores socio-demográficos y desempeño en la prueba.\n",
    "\n",
    "Pautas generales:\n",
    "* Seleccionar variables y proponer modelos acordes a dichas variables y al contexto del problema.\n",
    "* Utilizar los paquetes StatsModels y Scikit Learn para indagar sobre los aspectos que contribuyen al éxito de los estudiantes. Particularmente, las clases correspondientes a regresión lineal y regresión logística, entre otras, pueden ser útiles.\n",
    "* Utilizar las métricas de evaluación de desempeño (disponibles en los paquetes mencionados), para concluir sobre la validez de los modelos propuestos.\n",
    "\n",
    "Preguntas guía:\n",
    "* ¿Existe algún sub-conjunto de variables socio-demográficas que explique razonablemente bien el desempeño de los estudiantes en la prueba?\n",
    "* Definiendo como \"estudiante en riesgo\" a quien tenga un puntaje por debajo del percentil $\\alpha$ en más de la mitad de las áreas de la prueba, ¿cuáles variables socio-demográficas permitirían \"predecir\" si un estudiante pertenecerá a dicho grupo?\n",
    "\n",
    "El entregable de esta misión es un reporte sobre el desempeño de los modelos propuestos para abordar al menos una de las preguntas guía planteadas, acompañado de una conclusión sobre los resultados del modelo (si son válidos) en el contexto de la problemática planteada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Desarrollar una herramienta interactiva de análisis\n",
    "\n",
    "Esta misión consiste en desarrollar una herramienta interactiva sencilla (que sea relevante en el contexto del problema) a partir de alguno de los análisis realizados en las secciones 2 o 3.\n",
    "\n",
    "Pautas generales:\n",
    "* Seleccionar uno de los análisis previos que pueda verse enriquecido con alguna característica de interactividad.\n",
    "* Seleccionar los parámetros que el usuario podrá cambiar.\n",
    "* Desarrollar las funciones que se deben ejecutar con cada acción del usuario.\n",
    "* Utilizar los paquetes `ipywidgets` o `panel` para implementar la herramienta.\n",
    "\n",
    "Pregunta guía:\n",
    "* ¿Cuál(es) es la pregunta que el usuario podrá hacerle a la herramienta, y cómo aporta al análisis?\n",
    "* ¿Qué aprendizajes clave puede explorar u obtener el usuario con esta herramienta basada en los datos?\n",
    "\n",
    "El entregable de esta misión es la herramienta implementada, acompañada de las instrucciones necesarias para que un usuario la pueda utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
